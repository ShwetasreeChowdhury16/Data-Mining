{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed\n",
    "from random import randrange\n",
    "from csv import reader\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, sampleSize, n_trees,n_features, maxDepth,partitions,minSize):\n",
    "        self.maxDepth = maxDepth\n",
    "        self.partitions = partitions\n",
    "        self.minSize = minSize\n",
    "        self.sampleSize = sampleSize\n",
    "        self.n_trees = n_trees\n",
    "        self.n_features = n_features\n",
    "        self.dt = DecisionTree(self.maxDepth,\n",
    "                            self.partitions,\n",
    "                            self.minSize,\n",
    "                            self.n_features)\n",
    "        \n",
    "    def run(self,train_set, test_set):\n",
    "        trees = list()\n",
    "        np.random.seed(11)\n",
    "        for i in range(self.n_trees):\n",
    "            sample = self.subsample(train_set)\n",
    "            tree = self.dt.buildDecisionTree(sample)\n",
    "            trees.append(tree)\n",
    "        predictions = [self.baggingPredict(trees, row) for row in test_set]\n",
    "        actual = np.array(test_set)[:,len(test_set[0])-1]\n",
    "        Accuracy,Precision,Recall,F1_Score = self.dt.evaluatePerformance(actual, predictions)\n",
    "        return Accuracy,Precision,Recall,F1_Score\n",
    "             \n",
    "    # Make a prediction with a list of bagged trees\n",
    "    def baggingPredict(self,trees, row):\n",
    "        predictions = [self.dt.predict(tree, row) for tree in trees]\n",
    "        return max(set(predictions), key=predictions.count)\n",
    "\n",
    "    def subsample(self,dataset):\n",
    "        sample = list()\n",
    "        n_sample = round(len(dataset) * self.sampleSize)\n",
    "        while len(sample) < n_sample:\n",
    "            index = randrange(len(dataset))\n",
    "            sample.append(dataset[index])\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, maxDepth,partitions,minSize,n_features = None):\n",
    "        self.maxDepth = maxDepth\n",
    "        self.partitions = partitions\n",
    "        self.minSize = minSize\n",
    "        self.n_features = n_features\n",
    "         \n",
    "    # Calculate accuracy percentage\n",
    "    def calculateAccuracyMetrics(self,actual, predicted):\n",
    "        correct = 0\n",
    "        for i in range(len(actual)):\n",
    "            if actual[i] == predicted[i]:\n",
    "                correct += 1\n",
    "        return correct / float(len(actual)) * 100.0\n",
    "    \n",
    "    def evaluatePerformance(self,y_test, predictedLabelList):\n",
    "        data = {'Predicted': predictedLabelList ,\n",
    "                'Actual':  y_test  \n",
    "               }\n",
    "\n",
    "        df = pd.DataFrame(data, columns=['Actual','Predicted'])\n",
    "\n",
    "        confusion_matrix = pd.crosstab(df['Actual'], df['Predicted'])\n",
    "\n",
    "        tn=confusion_matrix[0][0]\n",
    "        fn=confusion_matrix[0][1]\n",
    "        fp=confusion_matrix[1][0]\n",
    "        tp=confusion_matrix[1][1]\n",
    "\n",
    "        Accuracy=(tp+tn)/(tp+tn+fp+fn)*100\n",
    "        Precision=(tp)/(tp+fp)\n",
    "        Recall=(tp)/(tp+fn)\n",
    "        F1_Score= 2*((Recall*Precision)/(Recall + Precision))\n",
    "        #print(\"TP:\",tp,\" TN:\",tn,\" FN:\",fn,\" FP:\",fp)\n",
    "        return Accuracy,Precision,Recall,F1_Score\n",
    "    \n",
    "    # Evaluate an algorithm using a cross validation split\n",
    "    def fit(self,train_set,test_set):\n",
    "        predicted = self.getDecisionTree(train_set, test_set)\n",
    "        actual = np.array(test_set)[:,len(test_set[0])-1]\n",
    "        Accuracy,Precision,Recall,F1_Score = self.evaluatePerformance(actual, predicted)\n",
    "        return Accuracy,Precision,Recall,F1_Score\n",
    "    \n",
    "    # Split a dataset based on an attribute and an attribute value\n",
    "    def doRandomSplit(self,index, value, dataset):\n",
    "        left = []\n",
    "        right = []\n",
    "        _ = [left.append(row) if row[index] < value else right.append(row) for row in dataset]\n",
    "        return left, right\n",
    "    \n",
    "    # Calculate the Gini index for a split dataset\n",
    "    def calGiniIndex(self,groups, labels):\n",
    "        # total gives the summation of all the instances combining all groups\n",
    "        total = float(sum([len(group) for group in groups]))\n",
    "        # initialise gini to zero\n",
    "        gini = 0.0\n",
    "        for group in groups:\n",
    "            # gives the elements belonging to each of the group\n",
    "            group_size = float(len(group))\n",
    "            # ignores if the size is 0\n",
    "            if group_size == 0:\n",
    "                continue\n",
    "            # initializing score to zero\n",
    "            score = 0.0\n",
    "            for label in labels:\n",
    "                # calculate the score for each of the data split\n",
    "                p = [row[-1] for row in group].count(label) / group_size\n",
    "                score += p * p\n",
    "            # weight the group score by its relative size\n",
    "            gini += (1.0 - score) * (group_size / total)\n",
    "        return gini\n",
    "    \n",
    "    # Select the best split point for a dataset\n",
    "    def findBestSplit(self,dataset):\n",
    "        # list pf different labels in the last column of the data\n",
    "        labels = list(set(row[-1] for row in dataset))\n",
    "        b_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
    "        if self.n_features == None:\n",
    "            for index in range(len(dataset[0])-1):\n",
    "                for row in dataset:\n",
    "                    groups = self.doRandomSplit(index, row[index], dataset)\n",
    "                    gini = self.calGiniIndex(groups, labels)\n",
    "                    if gini < b_score:\n",
    "                        #When selecting the best split and using it as a new node for the tree we will\n",
    "                        #store the index of the chosen attribute, the value of that attribute by \n",
    "                        #which to split and the two groups of data split by the chosen split point\n",
    "                        b_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
    "        else:\n",
    "            features = list()\n",
    "            while len(features) < self.n_features:\n",
    "                index = randrange(len(dataset[0])-1)\n",
    "                if index not in features:\n",
    "                    features.append(index)\n",
    "            for index in features:\n",
    "                for row in dataset:\n",
    "                    groups = self.test_split(index, row[index], dataset)\n",
    "                    gini = self.calGiniIndex(groups, labels)\n",
    "                    if gini < b_score:\n",
    "                        #When selecting the best split and using it as a new node for the tree we will\n",
    "                        #store the index of the chosen attribute, the value of that attribute by \n",
    "                        #which to split and the two groups of data split by the chosen split point\n",
    "                        b_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
    "        return {'index':b_index, 'value':b_value, 'groups':b_groups, 'gini':b_score}\n",
    "    \n",
    "    # Create a terminal node value\n",
    "    def leaf(self,group):\n",
    "        outcomes = [row[-1] for row in group]\n",
    "        return max(set(outcomes), key=outcomes.count)\n",
    "    \n",
    "    # Create child splits for a node or make leaf\n",
    "    def split(self,node,depth):\n",
    "        # the two groups of data split by the node are extracted for use\n",
    "        left, right = node['groups']\n",
    "        # check for a no split\n",
    "        # if either the left group or the right group is empty then we assign it as the leaf node\n",
    "        if not left or not right:\n",
    "            node['left'] = node['right'] = self.leaf(left + right)\n",
    "            return\n",
    "        # check for max depth if the max depth is reached we agian create the leaf node\n",
    "        if depth >= self.maxDepth:\n",
    "            node['left'], node['right'] = self.leaf(left), self.leaf(right)\n",
    "            return\n",
    "        # We check if the the group of rows is too small . If it is too small then we again assign it as a leaf node\n",
    "        if len(left) <= self.minSize:\n",
    "            node['left'] = self.leaf(left)\n",
    "        else:\n",
    "        # if non of the conditions satisfy we recursively split the node in a similar fashion.\n",
    "            node['left'] = self.findBestSplit(left)\n",
    "            self.split(node['left'],depth+1)\n",
    "        # We check if the number of rows in each group is too small include it as aleaf node\n",
    "        if len(right) <= self.minSize:\n",
    "            node['right'] = self.leaf(right)\n",
    "        else:\n",
    "        # if non of the above conditions satisfy we recursively split the data again\n",
    "            node['right'] = self.findBestSplit(right)\n",
    "            self.split(node['right'], depth+1)\n",
    "     \n",
    "    # Split a dataset based on an attribute and an attribute value\n",
    "    def test_split(self,index, value, dataset):\n",
    "        left, right = list(), list()\n",
    "        for row in dataset:\n",
    "            if row[index] < value:\n",
    "                left.append(row)\n",
    "            else:\n",
    "                right.append(row)\n",
    "        return left, right\n",
    "\n",
    "    # Build a decision tree\n",
    "    def buildDecisionTree(self,train):\n",
    "        root = self.findBestSplit(train)\n",
    "        self.split(root, 1)\n",
    "        #print(\"\\n ***********Decision Tree***********\\n\")\n",
    "        #print('Best Split for Feature%d < %.3f Gini=%.3f' % ((root['index']+1), root['value'], root['gini']))\n",
    "        #print(\"\\n\")\n",
    "        #self.printTree(root,self.maxDepth)\n",
    "        return root\n",
    "    \n",
    "    # Make a prediction with a decision tree\n",
    "    def predict(self,node, row):\n",
    "        #We must check if a child node is either a terminal value to be returned as the prediction, \n",
    "        #or if it is a dictionary node containing another level of the tree to be considered.\n",
    "        if row[node['index']] < node['value']:\n",
    "            # checks if the object is an instance of another instance\n",
    "            if isinstance(node['left'], dict):\n",
    "                return self.predict(node['left'], row)\n",
    "            else:\n",
    "                return node['left']\n",
    "        else:\n",
    "            # checks if the object is an instance of another instance\n",
    "            if isinstance(node['right'], dict):\n",
    "                return self.predict(node['right'], row)\n",
    "            else:\n",
    "                return node['right']\n",
    "            \n",
    "    # Classification and Regression Tree Algorithm\n",
    "    def getDecisionTree(self,train, test):\n",
    "        tree = self.buildDecisionTree(train)\n",
    "        predictions = list()\n",
    "        for row in test:\n",
    "            prediction = self.predict(tree, row)\n",
    "            predictions.append(prediction)\n",
    "        return(predictions)\n",
    "    \n",
    "    # Print a decision tree\n",
    "    def printTree(self,node, depth=0,level=0):\n",
    "        if isinstance(node, dict):\n",
    "            print('%s%s%d%s[Feature %d < %.3f]' % ((depth*' ','Level ',level+1,':', (node['index']+1), node['value'])))\n",
    "            self.printTree(node['left'], depth+1,level+1)\n",
    "            self.printTree(node['right'], depth+1,level+1)\n",
    "        else:\n",
    "            print('%s[%s]' % (((depth+7)*' ', node)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a dataset into n partitions so that we can calculate the cost based on different splits\n",
    "def doCrossValidation(dataset,partitions):\n",
    "    splits = list()\n",
    "    datasetCopy = list(dataset)\n",
    "    chunkSize = len(datasetCopy) // partitions\n",
    "    leftOver = len(datasetCopy) % partitions\n",
    "    start = 0\n",
    "    for i in range(partitions):\n",
    "        if i < leftOver:\n",
    "            end = start + chunkSize + 1\n",
    "        else:\n",
    "            end = start + chunkSize\n",
    "        splits.append(datasetCopy[start:end])\n",
    "        start = end\n",
    "    return splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToFloat(sequence):\n",
    "    for item in sequence:\n",
    "        try:\n",
    "            yield float(item)\n",
    "        except ValueError as e:\n",
    "            yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      "Trees: 5\n",
      "accuracy is :  94.69026548672566\n",
      "precision is :  0.972972972972973\n",
      "recall is :  0.8780487804878049\n",
      "fmeasure is :  0.923076923076923\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "fmeasure = []\n",
    "seed(11)\n",
    "\n",
    "original_data = pd.read_csv('project3_dataset1.txt', delimiter=\"\\t\", header=None)\n",
    "#print(original_data.iloc[0])\n",
    "obj_df = original_data.select_dtypes(include=['object']).copy()\n",
    "obj_df = obj_df.apply(LabelEncoder().fit_transform)\n",
    "for col in obj_df:\n",
    "    original_data[col] = obj_df[col]\n",
    "#print(original_data.iloc[0])\n",
    "dataset = original_data.values\n",
    "\n",
    "simpleRFData = dataset\n",
    "numPartitions = 10\n",
    "maxDepth = 10\n",
    "minimumSize = 1\n",
    "sampleSize = 1.0\n",
    "n_features = int(math.sqrt(len(dataset[0])-1))\n",
    "n_trees = 5\n",
    "\n",
    "np.random.seed(11)\n",
    "np.random.shuffle(simpleRFData)\n",
    "lent = len(dataset)\n",
    "trrows = math.floor(0.8*lent)\n",
    "train_set = simpleRFData[0:trrows]\n",
    "test_set = simpleRFData[trrows:len(simpleRFData)-1]\n",
    "\n",
    "rf = RandomForest(sampleSize, n_trees,n_features, maxDepth,numPartitions,minimumSize)\n",
    "Accuracy,Precision,Recall,F1_Score = rf.run(train_set,test_set)\n",
    "\n",
    "recall.append(Recall)\n",
    "precision.append(Precision)\n",
    "fmeasure.append(F1_Score)\n",
    "accuracy.append(Accuracy)\n",
    "\n",
    "mean_accuracy = np.mean(accuracy)\n",
    "mean_precision = np.mean(precision)\n",
    "mean_recall = np.mean(recall)\n",
    "mean_fmeasure = np.mean(fmeasure)\n",
    "\n",
    "print('\\n \\nTrees: %d' % n_trees)\n",
    "print(\"accuracy is : \",mean_accuracy)\n",
    "print(\"precision is : \",mean_precision)\n",
    "print(\"recall is : \",mean_recall)\n",
    "print(\"fmeasure is : \",mean_fmeasure)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest using KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "********Fold 1*********\n",
      "\n",
      "Trees: 5\n",
      "accuracy is :  95.57522123893806\n",
      "precision is :  0.9230769230769231\n",
      "recall is :  0.9473684210526315\n",
      "fmeasure is :  0.935064935064935\n",
      "\n",
      "\n",
      "********Fold 2*********\n",
      "\n",
      "Trees: 5\n",
      "accuracy is :  96.46017699115043\n",
      "precision is :  0.9722222222222222\n",
      "recall is :  0.9210526315789473\n",
      "fmeasure is :  0.9459459459459458\n",
      "\n",
      "\n",
      "********Fold 3*********\n",
      "\n",
      "Trees: 5\n",
      "accuracy is :  96.46017699115043\n",
      "precision is :  1.0\n",
      "recall is :  0.8947368421052632\n",
      "fmeasure is :  0.9444444444444444\n",
      "\n",
      "\n",
      "********Fold 4*********\n",
      "\n",
      "Trees: 5\n",
      "accuracy is :  94.69026548672566\n",
      "precision is :  0.9\n",
      "recall is :  0.9473684210526315\n",
      "fmeasure is :  0.9230769230769231\n",
      "\n",
      "\n",
      "********Fold 5*********\n",
      "\n",
      "Trees: 5\n",
      "accuracy is :  96.46017699115043\n",
      "precision is :  0.9722222222222222\n",
      "recall is :  0.9210526315789473\n",
      "fmeasure is :  0.9459459459459458\n",
      "\n",
      "\n",
      "********Fold 6*********\n",
      "\n",
      "Trees: 5\n",
      "accuracy is :  96.46017699115043\n",
      "precision is :  0.9722222222222222\n",
      "recall is :  0.9210526315789473\n",
      "fmeasure is :  0.9459459459459458\n",
      "\n",
      "\n",
      "********Fold 7*********\n",
      "\n",
      "Trees: 5\n",
      "accuracy is :  96.46017699115043\n",
      "precision is :  0.9722222222222222\n",
      "recall is :  0.9210526315789473\n",
      "fmeasure is :  0.9459459459459458\n",
      "\n",
      "\n",
      "********Fold 8*********\n",
      "\n",
      "Trees: 5\n",
      "accuracy is :  92.03539823008849\n",
      "precision is :  0.9142857142857143\n",
      "recall is :  0.8421052631578947\n",
      "fmeasure is :  0.8767123287671234\n",
      "\n",
      "\n",
      "********Fold 9*********\n",
      "\n",
      "Trees: 5\n",
      "accuracy is :  96.46017699115043\n",
      "precision is :  0.9473684210526315\n",
      "recall is :  0.9473684210526315\n",
      "fmeasure is :  0.9473684210526315\n",
      "\n",
      "\n",
      "********Fold 10*********\n",
      "\n",
      "Trees: 5\n",
      "accuracy is :  93.80530973451327\n",
      "precision is :  0.8974358974358975\n",
      "recall is :  0.9210526315789473\n",
      "fmeasure is :  0.9090909090909091\n",
      "\n",
      " \n",
      "Mean accuracy is :  95.4867256637168\n",
      "Mean precision is :  0.9471055844740055\n",
      "Mean recall is :  0.9184210526315789\n",
      "Mean fmeasure is :  0.931954174528075\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "fmeasure = []\n",
    "seed(11)\n",
    "\n",
    "numPartitions = 10\n",
    "maxDepth = 10\n",
    "minimumSize = 1\n",
    "sampleSize = 1.0\n",
    "n_features = int(math.sqrt(len(dataset[0])-1))\n",
    "n_trees = 5\n",
    "\n",
    "kfoldRFData = dataset\n",
    "np.random.seed(11)\n",
    "np.random.shuffle(kfoldRFData)\n",
    "folds = doCrossValidation(kfoldRFData,numPartitions)\n",
    "\n",
    "krf = RandomForest(sampleSize, n_trees,n_features, maxDepth,numPartitions,minimumSize)\n",
    "\n",
    "for index,fold in enumerate(folds):\n",
    "    print(\"\\n\\n********Fold \"+str(index+1)+\"*********\")\n",
    "    ktrain_set = list(folds)\n",
    "    ktrain_set.pop(index)\n",
    "    ktrain_set = sum(ktrain_set, [])\n",
    "    ktest_set = fold\n",
    "    Accuracy,Precision,Recall,F1_Score = krf.run(train_set,test_set)\n",
    "    recall.append(Recall)\n",
    "    precision.append(Precision)\n",
    "    fmeasure.append(F1_Score)\n",
    "    accuracy.append(Accuracy)\n",
    "    print('\\nTrees: %d' % n_trees)\n",
    "    print(\"accuracy is : \",Accuracy)\n",
    "    print(\"precision is : \",Precision)\n",
    "    print(\"recall is : \",Recall)\n",
    "    print(\"fmeasure is : \",F1_Score)\n",
    "    \n",
    "mean_accuracy = np.mean(accuracy)\n",
    "mean_precision = np.mean(precision)\n",
    "mean_recall = np.mean(recall)\n",
    "mean_fmeasure = np.mean(fmeasure)\n",
    "\n",
    "print(\"\\n \\nMean accuracy is : \",mean_accuracy)\n",
    "print(\"Mean precision is : \",mean_precision)\n",
    "print(\"Mean recall is : \",mean_recall)\n",
    "print(\"Mean fmeasure is : \",mean_fmeasure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
