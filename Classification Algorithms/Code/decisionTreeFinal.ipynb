{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed\n",
    "from random import randrange\n",
    "from csv import reader\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, maxDepth,partitions,minSize):\n",
    "        self.maxDepth = maxDepth\n",
    "        self.partitions = partitions\n",
    "        self.minSize = minSize\n",
    "         \n",
    "    # Calculate accuracy percentage\n",
    "    def calculateAccuracyMetrics(self,actual, predicted):\n",
    "        correct = 0\n",
    "        for i in range(len(actual)):\n",
    "            if actual[i] == predicted[i]:\n",
    "                correct += 1\n",
    "        return correct / float(len(actual)) * 100.0\n",
    "    \n",
    "    def evaluatePerformance(self,y_test, predictedLabelList):\n",
    "        data = {'Predicted': predictedLabelList ,\n",
    "                'Actual':  y_test  \n",
    "               }\n",
    "\n",
    "        df = pd.DataFrame(data, columns=['Actual','Predicted'])\n",
    "\n",
    "        confusion_matrix = pd.crosstab(df['Actual'], df['Predicted'])\n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        print(confusion_matrix) \n",
    "\n",
    "        tn=confusion_matrix[0][0]\n",
    "        fn=confusion_matrix[0][1]\n",
    "        fp=confusion_matrix[1][0]\n",
    "        tp=confusion_matrix[1][1]\n",
    "\n",
    "        Accuracy=(tp+tn)/(tp+tn+fp+fn)*100\n",
    "        Precision=(tp)/(tp+fp)\n",
    "        Recall=(tp)/(tp+fn)\n",
    "        F1_Score= 2*((Recall*Precision)/(Recall + Precision))\n",
    "        #print(\"TP:\",tp,\" TN:\",tn,\" FN:\",fn,\" FP:\",fp)\n",
    "        return Accuracy,Precision,Recall,F1_Score\n",
    "    \n",
    "    # Evaluate an algorithm using a cross validation split\n",
    "    def fit(self,train_set,test_set):\n",
    "        predicted = self.getDecisionTree(train_set, test_set)\n",
    "        actual = np.array(test_set)[:,len(test_set[0])-1]\n",
    "        Accuracy,Precision,Recall,F1_Score = self.evaluatePerformance(actual, predicted)\n",
    "        return Accuracy,Precision,Recall,F1_Score\n",
    "    \n",
    "    # Split a dataset based on an attribute and an attribute value\n",
    "    def doRandomSplit(self,index, value, dataset):\n",
    "        left = []\n",
    "        right = []\n",
    "        _ = [left.append(row) if row[index] < value else right.append(row) for row in dataset]\n",
    "        return left, right\n",
    "    \n",
    "    # Calculate the Gini index for a split dataset\n",
    "    def calGiniIndex(self,groups, labels):\n",
    "        # total gives the summation of all the instances combining all groups\n",
    "        total = float(sum([len(group) for group in groups]))\n",
    "        # initialise gini to zero\n",
    "        gini = 0.0\n",
    "        for group in groups:\n",
    "            # gives the elements belonging to each of the group\n",
    "            group_size = float(len(group))\n",
    "            # ignores if the size is 0\n",
    "            if group_size == 0:\n",
    "                continue\n",
    "            # initializing score to zero\n",
    "            score = 0.0\n",
    "            for label in labels:\n",
    "                # calculate the score for each of the data split\n",
    "                p = [row[-1] for row in group].count(label) / group_size\n",
    "                score += p * p\n",
    "            # weight the group score by its relative size\n",
    "            gini += (1.0 - score) * (group_size / total)\n",
    "        return gini\n",
    "    \n",
    "    # Select the best split point for a dataset\n",
    "    def findBestSplit(self,dataset):\n",
    "        # list pf different labels in the last column of the data\n",
    "        labels = list(set(row[-1] for row in dataset))\n",
    "        b_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
    "        for index in range(len(dataset[0])-1):\n",
    "            for row in dataset:\n",
    "                groups = self.doRandomSplit(index, row[index], dataset)\n",
    "                gini = self.calGiniIndex(groups, labels)\n",
    "                if gini < b_score:\n",
    "                    #When selecting the best split and using it as a new node for the tree we will\n",
    "                    #store the index of the chosen attribute, the value of that attribute by \n",
    "                    #which to split and the two groups of data split by the chosen split point\n",
    "                    b_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
    "        return {'index':b_index, 'value':b_value, 'groups':b_groups, 'gini':b_score}\n",
    "    \n",
    "    # Create a terminal node value\n",
    "    def leaf(self,group):\n",
    "        outcomes = [row[-1] for row in group]\n",
    "        return max(set(outcomes), key=outcomes.count)\n",
    "    \n",
    "    # Create child splits for a node or make leaf\n",
    "    def split(self,node,depth):\n",
    "        # the two groups of data split by the node are extracted for use\n",
    "        left, right = node['groups']\n",
    "        # check for a no split\n",
    "        # if either the left group or the right group is empty then we assign it as the leaf node\n",
    "        if not left or not right:\n",
    "            node['left'] = node['right'] = self.leaf(left + right)\n",
    "            return\n",
    "        # check for max depth if the max depth is reached we agian create the leaf node\n",
    "        if depth >= self.maxDepth:\n",
    "            node['left'], node['right'] = self.leaf(left), self.leaf(right)\n",
    "            return\n",
    "        # We check if the the group of rows is too small . If it is too small then we again assign it as a leaf node\n",
    "        if len(left) <= self.minSize:\n",
    "            node['left'] = self.leaf(left)\n",
    "        else:\n",
    "        # if non of the conditions satisfy we recursively split the node in a similar fashion.\n",
    "            node['left'] = self.findBestSplit(left)\n",
    "            self.split(node['left'],depth+1)\n",
    "        # We check if the number of rows in each group is too small include it as aleaf node\n",
    "        if len(right) <= self.minSize:\n",
    "            node['right'] = self.leaf(right)\n",
    "        else:\n",
    "        # if non of the above conditions satisfy we recursively split the data again\n",
    "            node['right'] = self.findBestSplit(right)\n",
    "            self.split(node['right'], depth+1)\n",
    "            \n",
    "    # Build a decision tree\n",
    "    def buildDecisionTree(self,train):\n",
    "        root = self.findBestSplit(train)\n",
    "        self.split(root, 1)\n",
    "        return root\n",
    "    \n",
    "    # Make a prediction with a decision tree\n",
    "    def predict(self,node, row):\n",
    "        #We must check if a child node is either a terminal value to be returned as the prediction, \n",
    "        #or if it is a dictionary node containing another level of the tree to be considered.\n",
    "        if row[node['index']] < node['value']:\n",
    "            # checks if the object is an instance of another instance\n",
    "            if isinstance(node['left'], dict):\n",
    "                return self.predict(node['left'], row)\n",
    "            else:\n",
    "                return node['left']\n",
    "        else:\n",
    "            # checks if the object is an instance of another instance\n",
    "            if isinstance(node['right'], dict):\n",
    "                return self.predict(node['right'], row)\n",
    "            else:\n",
    "                return node['right']\n",
    "            \n",
    "    # Classification and Regression Tree Algorithm\n",
    "    def getDecisionTree(self,train, test):\n",
    "        tree = self.buildDecisionTree(train)\n",
    "        print(\"\\n ***********Decision Tree***********\\n\")\n",
    "        print('Best Split for Feature%d < %.3f Gini=%.3f' % ((tree['index']+1), tree['value'], tree['gini']))\n",
    "        print(\"\\n\")\n",
    "        self.printTree(tree,self.maxDepth)\n",
    "        predictions = list()\n",
    "        for row in test:\n",
    "            prediction = self.predict(tree, row)\n",
    "            predictions.append(prediction)\n",
    "        return(predictions)\n",
    "    \n",
    "    # Print a decision tree\n",
    "    def printTree(self,node, depth=0,level=0):\n",
    "        if isinstance(node, dict):\n",
    "            print('%s%s%d%s[Feature %d < %.3f]' % ((depth*' ','Level ',level+1,':', (node['index']+1), node['value'])))\n",
    "            self.printTree(node['left'], depth+1,level+1)\n",
    "            self.printTree(node['right'], depth+1,level+1)\n",
    "        else:\n",
    "            print('%s[%s]' % (((depth+7)*' ', node)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToFloat(sequence):\n",
    "    for item in sequence:\n",
    "        try:\n",
    "            yield float(item)\n",
    "        except ValueError as e:\n",
    "            yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a dataset into n partitions so that we can calculate the cost based on different splits\n",
    "def doCrossValidation(dataset,partitions):\n",
    "    splits = list()\n",
    "    datasetCopy = list(dataset)\n",
    "    chunkSize = len(datasetCopy) // partitions\n",
    "    leftOver = len(datasetCopy) % partitions\n",
    "    start = 0\n",
    "    for i in range(partitions):\n",
    "        if i < leftOver:\n",
    "            end = start + chunkSize + 1\n",
    "        else:\n",
    "            end = start + chunkSize\n",
    "        splits.append(datasetCopy[start:end])\n",
    "        start = end\n",
    "    return splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ***********Decision Tree***********\n",
      "\n",
      "Best Split for Feature9 < 51.000 Gini=0.402\n",
      "\n",
      "\n",
      "   Level 1:[Feature 9 < 51.000]\n",
      "    Level 2:[Feature 2 < 0.520]\n",
      "     Level 3:[Feature 9 < 36.000]\n",
      "             [0.0]\n",
      "             [0.0]\n",
      "     Level 3:[Feature 6 < 69.000]\n",
      "             [0.0]\n",
      "             [1.0]\n",
      "    Level 2:[Feature 5 < 1.000]\n",
      "     Level 3:[Feature 2 < 7.770]\n",
      "             [0.0]\n",
      "             [1.0]\n",
      "     Level 3:[Feature 3 < 5.100]\n",
      "             [1.0]\n",
      "             [1.0]\n",
      "\n",
      "Confusion Matrix:\n",
      "Predicted  0.0  1.0\n",
      "Actual             \n",
      "0.0         55    6\n",
      "1.0         16   15\n",
      "\n",
      " \n",
      "Mean accuracy is :  76.08695652173914\n",
      "Mean precision is :  0.7142857142857143\n",
      "Mean recall is :  0.4838709677419355\n",
      "Mean fmeasure is :  0.5769230769230769\n"
     ]
    }
   ],
   "source": [
    "# Test CART on project 3 dataset\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "fmeasure = []\n",
    "\n",
    "# initialization of the partitions and the max depth of the trees\n",
    "numPartitions = 10\n",
    "seed(11)\n",
    "# max_depth and min_size tells us when we stop growing the tree\n",
    "maxDepth = 3\n",
    "\n",
    "crossVal = False\n",
    "minimumSize = 1\n",
    "\n",
    "original_data = pd.read_csv('project3_dataset2.txt', delimiter=\"\\t\", header=None)\n",
    "#print(original_data.iloc[0])\n",
    "obj_df = original_data.select_dtypes(include=['object']).copy()\n",
    "obj_df = obj_df.apply(LabelEncoder().fit_transform)\n",
    "for col in obj_df:\n",
    "    original_data[col] = obj_df[col]\n",
    "#print(original_data.iloc[0])\n",
    "dataset = original_data.values\n",
    "#data = dataset.tolist()\n",
    "#data = [list(convertToFloat(sublist)) for sublist in dataset]\n",
    "\n",
    "decisionTreeData = dataset\n",
    "# evaluate algorithm\n",
    "dt = DecisionTree(maxDepth,numPartitions,minimumSize)\n",
    "np.random.seed(11)\n",
    "np.random.shuffle(decisionTreeData)\n",
    "lent = len(dataset)\n",
    "trrows = math.floor(0.8*lent)\n",
    "train_set = decisionTreeData[0:trrows]\n",
    "test_set = decisionTreeData[trrows:len(decisionTreeData)-1]\n",
    "Accuracy,Precision,Recall,F1_Score = dt.fit(train_set,test_set)\n",
    "recall.append(Recall)\n",
    "precision.append(Precision)\n",
    "fmeasure.append(F1_Score)\n",
    "accuracy.append(Accuracy)\n",
    "\n",
    "#print('Scores: %s' % scores)\n",
    "#print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))\n",
    "\n",
    "mean_accuracy = np.mean(accuracy)\n",
    "mean_precision = np.mean(precision)\n",
    "mean_recall = np.mean(recall)\n",
    "mean_fmeasure = np.mean(fmeasure)\n",
    "\n",
    "print(\"\\n \\nMean accuracy is : \",mean_accuracy)\n",
    "print(\"Mean precision is : \",mean_precision)\n",
    "print(\"Mean recall is : \",mean_recall)\n",
    "print(\"Mean fmeasure is : \",mean_fmeasure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Fold Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ***********Decision Tree***********\n",
      "\n",
      "Best Split for Feature9 < 49.000 Gini=0.406\n",
      "\n",
      "\n",
      "   Level 1:[Feature 9 < 49.000]\n",
      "    Level 2:[Feature 9 < 31.000]\n",
      "     Level 3:[Feature 2 < 0.520]\n",
      "             [0.0]\n",
      "             [0.0]\n",
      "     Level 3:[Feature 6 < 69.000]\n",
      "             [0.0]\n",
      "             [1.0]\n",
      "    Level 2:[Feature 5 < 1.000]\n",
      "     Level 3:[Feature 2 < 7.770]\n",
      "             [0.0]\n",
      "             [1.0]\n",
      "     Level 3:[Feature 3 < 2.460]\n",
      "             [0.0]\n",
      "             [1.0]\n",
      "\n",
      "Confusion Matrix:\n",
      "Predicted  0.0  1.0\n",
      "Actual             \n",
      "0.0         29    4\n",
      "1.0          5    9\n",
      "Accuracy:  80.85106382978722\n",
      "\n",
      " ***********Decision Tree***********\n",
      "\n",
      "Best Split for Feature9 < 51.000 Gini=0.397\n",
      "\n",
      "\n",
      "   Level 1:[Feature 9 < 51.000]\n",
      "    Level 2:[Feature 9 < 31.000]\n",
      "     Level 3:[Feature 2 < 0.520]\n",
      "             [0.0]\n",
      "             [0.0]\n",
      "     Level 3:[Feature 6 < 69.000]\n",
      "             [0.0]\n",
      "             [1.0]\n",
      "    Level 2:[Feature 5 < 1.000]\n",
      "     Level 3:[Feature 2 < 7.770]\n",
      "             [0.0]\n",
      "             [1.0]\n",
      "     Level 3:[Feature 3 < 5.080]\n",
      "             [1.0]\n",
      "             [1.0]\n",
      "\n",
      "Confusion Matrix:\n",
      "Predicted  0.0  1.0\n",
      "Actual             \n",
      "0.0         30    3\n",
      "1.0          4   10\n",
      "Accuracy:  85.1063829787234\n",
      "\n",
      " ***********Decision Tree***********\n",
      "\n",
      "Best Split for Feature9 < 51.000 Gini=0.400\n",
      "\n",
      "\n",
      "   Level 1:[Feature 9 < 51.000]\n",
      "    Level 2:[Feature 2 < 0.500]\n",
      "     Level 3:[Feature 1 < 188.000]\n",
      "             [0.0]\n",
      "             [1.0]\n",
      "     Level 3:[Feature 6 < 69.000]\n",
      "             [0.0]\n",
      "             [1.0]\n",
      "    Level 2:[Feature 2 < 7.600]\n",
      "     Level 3:[Feature 5 < 1.000]\n",
      "             [0.0]\n",
      "             [1.0]\n",
      "     Level 3:[Feature 4 < 29.350]\n",
      "             [1.0]\n",
      "             [1.0]\n",
      "\n",
      "Confusion Matrix:\n",
      "Predicted  0.0  1.0\n",
      "Actual             \n",
      "0.0         23    5\n",
      "1.0          6   12\n",
      "Accuracy:  76.08695652173914\n",
      "\n",
      " ***********Decision Tree***********\n",
      "\n",
      "Best Split for Feature9 < 51.000 Gini=0.396\n",
      "\n",
      "\n",
      "   Level 1:[Feature 9 < 51.000]\n",
      "    Level 2:[Feature 9 < 31.000]\n",
      "     Level 3:[Feature 1 < 108.000]\n",
      "             [1.0]\n",
      "             [0.0]\n",
      "     Level 3:[Feature 6 < 70.000]\n",
      "             [0.0]\n",
      "             [1.0]\n",
      "    Level 2:[Feature 5 < 1.000]\n",
      "     Level 3:[Feature 2 < 7.770]\n",
      "             [0.0]\n",
      "             [1.0]\n",
      "     Level 3:[Feature 3 < 5.080]\n",
      "             [1.0]\n",
      "             [1.0]\n",
      "\n",
      "Confusion Matrix:\n",
      "Predicted  0.0  1.0\n",
      "Actual             \n",
      "0.0         22    6\n",
      "1.0         11    7\n",
      "Accuracy:  63.04347826086957\n",
      "\n",
      " ***********Decision Tree***********\n",
      "\n",
      "Best Split for Feature9 < 50.000 Gini=0.397\n",
      "\n",
      "\n",
      "   Level 1:[Feature 9 < 50.000]\n",
      "    Level 2:[Feature 9 < 32.000]\n",
      "     Level 3:[Feature 8 < 11.110]\n",
      "             [0.0]\n",
      "             [0.0]\n",
      "     Level 3:[Feature 6 < 69.000]\n",
      "             [0.0]\n",
      "             [1.0]\n",
      "    Level 2:[Feature 5 < 1.000]\n",
      "     Level 3:[Feature 2 < 8.140]\n",
      "             [0.0]\n",
      "             [1.0]\n",
      "     Level 3:[Feature 2 < 0.900]\n",
      "             [0.0]\n",
      "             [1.0]\n",
      "\n",
      "Confusion Matrix:\n",
      "Predicted  0.0  1.0\n",
      "Actual             \n",
      "0.0         24    3\n",
      "1.0         12    7\n",
      "Accuracy:  67.3913043478261\n",
      "\n",
      " ***********Decision Tree***********\n",
      "\n",
      "Best Split for Feature9 < 51.000 Gini=0.404\n",
      "\n",
      "\n",
      "   Level 1:[Feature 9 < 51.000]\n",
      "    Level 2:[Feature 9 < 30.000]\n",
      "     Level 3:[Feature 2 < 0.520]\n",
      "             [0.0]\n",
      "             [0.0]\n",
      "     Level 3:[Feature 6 < 69.000]\n",
      "             [0.0]\n",
      "             [1.0]\n",
      "    Level 2:[Feature 2 < 7.500]\n",
      "     Level 3:[Feature 5 < 1.000]\n",
      "             [0.0]\n",
      "             [1.0]\n",
      "     Level 3:[Feature 1 < 160.000]\n",
      "             [1.0]\n",
      "             [1.0]\n",
      "\n",
      "Confusion Matrix:\n",
      "Predicted  0.0  1.0\n",
      "Actual             \n",
      "0.0         27    3\n",
      "1.0          8    8\n",
      "Accuracy:  76.08695652173914\n",
      "\n",
      " ***********Decision Tree***********\n",
      "\n",
      "Best Split for Feature9 < 39.000 Gini=0.401\n",
      "\n",
      "\n",
      "   Level 1:[Feature 9 < 39.000]\n",
      "    Level 2:[Feature 2 < 1.500]\n",
      "     Level 3:[Feature 9 < 32.000]\n",
      "             [0.0]\n",
      "             [0.0]\n",
      "     Level 3:[Feature 3 < 6.410]\n",
      "             [0.0]\n",
      "             [1.0]\n",
      "    Level 2:[Feature 5 < 1.000]\n",
      "     Level 3:[Feature 2 < 7.770]\n",
      "             [0.0]\n",
      "             [1.0]\n",
      "     Level 3:[Feature 3 < 8.120]\n",
      "             [1.0]\n",
      "             [1.0]\n",
      "\n",
      "Confusion Matrix:\n",
      "Predicted  0.0  1.0\n",
      "Actual             \n",
      "0.0         21    5\n",
      "1.0          6   14\n",
      "Accuracy:  76.08695652173914\n",
      "\n",
      " ***********Decision Tree***********\n",
      "\n",
      "Best Split for Feature9 < 50.000 Gini=0.404\n",
      "\n",
      "\n",
      "   Level 1:[Feature 9 < 50.000]\n",
      "    Level 2:[Feature 9 < 31.000]\n",
      "     Level 3:[Feature 1 < 198.000]\n",
      "             [0.0]\n",
      "             [1.0]\n",
      "     Level 3:[Feature 6 < 69.000]\n",
      "             [0.0]\n",
      "             [1.0]\n",
      "    Level 2:[Feature 3 < 2.460]\n",
      "     Level 3:[Feature 1 < 156.000]\n",
      "             [0.0]\n",
      "             [0.0]\n",
      "     Level 3:[Feature 5 < 1.000]\n",
      "             [0.0]\n",
      "             [1.0]\n",
      "\n",
      "Confusion Matrix:\n",
      "Predicted  0.0  1.0\n",
      "Actual             \n",
      "0.0         31    6\n",
      "1.0          3    6\n",
      "Accuracy:  80.43478260869566\n",
      "\n",
      " ***********Decision Tree***********\n",
      "\n",
      "Best Split for Feature9 < 50.000 Gini=0.381\n",
      "\n",
      "\n",
      "   Level 1:[Feature 9 < 50.000]\n",
      "    Level 2:[Feature 2 < 0.520]\n",
      "     Level 3:[Feature 7 < 17.750]\n",
      "             [1.0]\n",
      "             [0.0]\n",
      "     Level 3:[Feature 3 < 3.950]\n",
      "             [0.0]\n",
      "             [0.0]\n",
      "    Level 2:[Feature 5 < 1.000]\n",
      "     Level 3:[Feature 2 < 7.770]\n",
      "             [0.0]\n",
      "             [1.0]\n",
      "     Level 3:[Feature 3 < 2.460]\n",
      "             [0.0]\n",
      "             [1.0]\n",
      "\n",
      "Confusion Matrix:\n",
      "Predicted  0.0  1.0\n",
      "Actual             \n",
      "0.0         23    7\n",
      "1.0         13    3\n",
      "Accuracy:  56.52173913043478\n",
      "\n",
      " ***********Decision Tree***********\n",
      "\n",
      "Best Split for Feature9 < 51.000 Gini=0.398\n",
      "\n",
      "\n",
      "   Level 1:[Feature 9 < 51.000]\n",
      "    Level 2:[Feature 9 < 31.000]\n",
      "     Level 3:[Feature 2 < 0.520]\n",
      "             [0.0]\n",
      "             [0.0]\n",
      "     Level 3:[Feature 6 < 69.000]\n",
      "             [0.0]\n",
      "             [1.0]\n",
      "    Level 2:[Feature 5 < 1.000]\n",
      "     Level 3:[Feature 2 < 7.770]\n",
      "             [0.0]\n",
      "             [1.0]\n",
      "     Level 3:[Feature 3 < 5.080]\n",
      "             [1.0]\n",
      "             [1.0]\n",
      "\n",
      "Confusion Matrix:\n",
      "Predicted  0.0  1.0\n",
      "Actual             \n",
      "0.0         26    4\n",
      "1.0          8    8\n",
      "Accuracy:  73.91304347826086\n",
      "\n",
      " \n",
      "Mean accuracy is :  73.5522664199815\n",
      "Mean precision is :  0.6336663852143729\n",
      "Mean recall is :  0.5335286131996659\n",
      "Mean fmeasure is :  0.5711660901204839\n"
     ]
    }
   ],
   "source": [
    "numPartitions = 10\n",
    "seed(11)\n",
    "maxDepth = 3\n",
    "minimumSize = 1\n",
    "kfoldData = dataset\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "fmeasure = []\n",
    "np.random.seed(11)\n",
    "np.random.shuffle(kfoldData)\n",
    "folds = doCrossValidation(kfoldData,numPartitions)\n",
    "\n",
    "kdt = DecisionTree(maxDepth,numPartitions,minimumSize)\n",
    "\n",
    "for index,fold in enumerate(folds):\n",
    "    ktrain_set = list(folds)\n",
    "    ktrain_set.pop(index)\n",
    "    ktrain_set = sum(ktrain_set, [])\n",
    "    ktest_set = fold\n",
    "    Accuracy,Precision,Recall,F1_Score = kdt.fit(ktrain_set,ktest_set)\n",
    "    recall.append(Recall)\n",
    "    precision.append(Precision)\n",
    "    fmeasure.append(F1_Score)\n",
    "    accuracy.append(Accuracy)\n",
    "    print(\"Accuracy: \",Accuracy)\n",
    "    \n",
    "mean_accuracy = np.mean(accuracy)\n",
    "mean_precision = np.mean(precision)\n",
    "mean_recall = np.mean(recall)\n",
    "mean_fmeasure = np.mean(fmeasure)\n",
    "\n",
    "print(\"\\n \\nMean accuracy is : \",mean_accuracy)\n",
    "print(\"Mean precision is : \",mean_precision)\n",
    "print(\"Mean recall is : \",mean_recall)\n",
    "print(\"Mean fmeasure is : \",mean_fmeasure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
